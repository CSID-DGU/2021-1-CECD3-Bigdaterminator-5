{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "179f625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t이쯤되면 이 삼인방 재평가 시급한거 아님????\t\t\n",
      "\t\t\t머니게임 한 번도 안 본 펨붕이 있으면 개추 ㅋㅋ;\t\t\n",
      "\t\t\t니갸르 폭로때매 파이언급이 많아지자 코트 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\t\t\n",
      "\t\t\t머니게임..... 다시 보니 ㄹㅇ 선녀인 장면.gif\t\t\n",
      "\t\t\t머니게임) 3천 받아놓고 0원 3명 불러다가 지 세탁질 시켜놓고 맘에 안든다고 뒤통수 갈겨?\t\t\n",
      "\t\t\t머니게임) 호감도 안가게 생긴 듣보잡 외국인은 왜 넣은거냐?\t\t\n",
      "\t\t\t머니게임) 아니 파이가 3천 벌었다고???\t\t\n",
      "\t\t\t머니게임 시즌2 최상의 멤버\t\t\n",
      "\t\t\t머니게임) 마지막 엔딩크레딧 웃음벨.jpg\t\t\n",
      "\t\t\t파이 퇴소이후 니갸르 발언 해석.jpg\t\t\n",
      "\t\t\t머니게임)) 파이가 나간이유 떳다...jpg\t\t\n",
      "\t\t\t머니게임 최종화를 보고 이해된 점\t\t\n",
      "\t\t\t오피셜) 머니게임 최종 우승자\t\t\n",
      "\t\t\t20.05.15. 파이 오프닝 토크 [머니게임 관련]\t\t\n",
      "\t\t\t이루리 조용히 있다가 6개월뒤에 커뮤 돌면서 고소장쓸것같음\t\t\n",
      "\t\t\t니갸르 폭로후 보니 소름돋는 장면\t\t\n",
      "\t\t\t실시간) 코트 채팅창\t\t\n",
      "\t\t\t배그하다 파이보는 코트 클립 영상 ㅋㅋㅋ\t\t\n",
      "\t\t\tn방향 3천미터 채팅본 코트반응 ㅋㅋㅋㅋㅋㅋㅋ\t\t\n",
      "\t\t\t파이 : 코트오빠 원래 한 말에 책임 지시는 편인가요???\t\t\n",
      "\t\t\tㅋㅋㅋ파이가 개꿀인거 같지?\t\t\n",
      "\t\t\t지금 니갸르 폭로보고 제대로 느낀점.jpg\t\t\n",
      "\t\t\t머니게임 최종빌런 밝혀짐\t\t\n",
      "\t\t\t머니게임 촬영 끝낸 당시… 파이…jpg\t\t\n",
      "\t\t\t실시간 파이 상황 ㅋㅋㅋ\t\t\n",
      "\t\t\t머니게임) 아까 니갸르 방송에 이루리 남친 옴.jpg\t\t\n",
      "\t\t\t머니게임 2주도 저렇게 힘든데\t\t\n",
      "\t\t\t씹 ㅋㅋㅋㅋ 머니게임 결말 예언한 놈 찾았다\t\t\n",
      "\t\t\t파이는 얘는 진짜..ㄷㄷ\t\t\n",
      "\t\t\t니갸르 폭로 8줄 요약 ㄷㄷㄷㄷㄷㄷ.jpg\t\t\n",
      "\t\t\t엠팍좌 6년전 이루리 예언...ㄷㄷ\t\t\n",
      "\t\t\t머니게임)니갸르:육지담이 2천만원 요구함\t\t\n",
      "\t\t\t육지담 유튜브 재개하자마자 다시 나락 위기\t\t\n",
      "\t\t\t니갸르: 착한 사람 믿지마세요. 이루리랑 대화 안한 이유\t\t\n",
      "\t\t\t머니게임좀 시발 그만 올려라\t\t\n",
      "\t\t\t머니게임 실시간) 이루리 & N빵에 대한 최종해명 정리\t\t\n",
      "\t\t\t머니게임)파이 더 역겨워진점 ㅋㅋ.jpg\t\t\n",
      "\t\t\t현시각 이루리 인스타 공손한 테러범 출몰ㅋㅋㅋㅋㅋㅋㅋㅋ .jpg\t\t\n",
      "\t\t\t니갸르 안아주는 이루리 보고 쌍욕ㄷㄷㄷ.avi\t\t\n",
      "\t\t\t월 몇천 버는 사람들이 거지 하꼬 유튜버들 농락한거임 ㅋㅋ.jpg\t\t\n",
      "\t\t\t실시간 파이 맨탈붕괴직전\t\t\n",
      "\t\t\t현시각.... 개꿀 듀오\t\t\n",
      "\t\t\t다음주 펨코 폭발 ㄷㄷ\t\t\n",
      "\t\t\t머니게임)) 돈 분배 오피셜. TXT\t\t\n",
      "\t\t\t[머니게임] 근데 육지담은 왜 욕먹는거임?\t\t\n",
      "\t\t\t머니게임) 이루리.. 진정성 보이던 장면.jpg\t\t\n",
      "\t\t\t니갸르 가장 불쌍한 점\t\t\n",
      "\t\t\t어느회사 여자화장실 블라인드글\t\t\n",
      "\t\t\t머니게임)) 8화 결말 요약...jpg\t\t\n",
      "\t\t\t와 님들 파이 사과문 뜸 ㄷㄷㄷㄷㄷㄷㄷㄷㄷㄷㄷㄷ\t\t\n",
      "\t\t\t니갸르: 카톡 내용까면 경찰서까지 가야한다\t\t\n",
      "\t\t\t전기가 ㅂㅅ인이유\t\t\n",
      "\t\t\t현 시간부로 '니갸르'에 대한 지지를 철회한다\t\t\n",
      "\t\t\t이루리曰남은 3일동안 서로 의지 많이했다 -전공가 세탁방송中....\t\t\n",
      "\t\t\t파이 멘탈 장난아닌듯ㅋㅋㅋㅋㅋ\t\t\n",
      "\t\t\t실시간 논리왕전기 상황ㅋㅋ\t\t\n",
      "\t\t\t니갸르 피셜) 마지막날 이루리랑 개싸움\t\t\n",
      "\t\t\t'촌스럽게 아침에 출근하냐'는 벤츠녀.png\t\t\n",
      "\t\t\t이루리 : 착한아이 증후군 때문에 고민이 많았다\t\t\n",
      "\t\t\t머니게임 스포주의) 이랬으면 씹극락 ㅇㅈ?\t\t\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "503 Server Error: Internal Server Error for url: https://www.fmkorea.com/index.php?mid=best2&listStyle=list&document_srl=3599753893",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3183902f3210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendcoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mhtml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 503 Server Error: Internal Server Error for url: https://www.fmkorea.com/index.php?mid=best2&listStyle=list&document_srl=3599753893"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver import Chrome\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from knolpy.tag import Hannanum\n",
    "\n",
    "excel_file = openpyxl.Workbook()\n",
    "excel_sheet = excel_file.active\n",
    "\n",
    "browser = Chrome()\n",
    "\n",
    "title = []\n",
    "links = []\n",
    "texts = []\n",
    "comments = []\n",
    "\n",
    "for i in range(1,2):\n",
    "    browser.get(\"https://www.fmkorea.com/index.php?mid=best2&listStyle=list&page=\" + str(i))\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    result = soup.find('div', {'class': 'content_dummy'}).findAll('td', class_='hotdeal_var8')\n",
    "    #result= soup.find_all(\"td\", class_=\"hotdeal_var8\")\n",
    "    #print('length of result : ' + str(len(result)))\n",
    "    for td in result:\n",
    "        f_link = td.findAll('a', class_='hx')\n",
    "        for a in f_link:\n",
    "            conlink = 'https://www.fmkorea.com' + a.get('href')\n",
    "            links.append(conlink)\n",
    "\n",
    "    for i in result:\n",
    "        i = BeautifulSoup(str(i), 'html.parser')\n",
    "        try:\n",
    "            print(i.find(\"a\", class_=\"hx\").text)\n",
    "            #title = re.sub('[-=+_★♥♡,#/\\?:╋^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》—;]','','gif','jpg','txt',title)\n",
    "            title.append(i.find(\"a\", class_=\"hx\").text)\n",
    "        except:\n",
    "            print('Occur Error !')\n",
    "#print({'url':links})\n",
    "\n",
    "#본문\n",
    "for i in links:\n",
    "    try:\n",
    "        res = requests.get(i)\n",
    "        res.raise_for_status()\n",
    "        res.endcoding = None\n",
    "        html2 = res.text\n",
    "\n",
    "        soup = BeautifulSoup(html2, 'html.parser')\n",
    "        contentArea = soup.find(\"div\", {\"class\" : \"content_dummy\"})\n",
    "        parags = contentArea.findAll(\"div\", {\"class\" : \"rd_body clear\"})\n",
    "\n",
    "        content = \"\"\n",
    "\n",
    "        for parag in parags:\n",
    "            content += parag.text\n",
    "        #content = re.sub('[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', content)\n",
    "        #content = re.sub('[ㅋ]', '', content)\n",
    "        #content = re.sub('[&nbsp;|\\n|\\t|\\r]', '', content)\n",
    "        #content = re.sub('[\\xa0]', '', content)\n",
    "        #content = re.sub('[-=+_★♥♡,#/\\?:╋^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》—;]', '', content)\n",
    "        #content = spacing(content)\n",
    "\n",
    "        texts.append(content)\n",
    "   \n",
    "    except HTTPError as e:\n",
    "        texts.append('')\n",
    "    except URLError as e:\n",
    "        texts.append('')\n",
    "    except AttributeError as e:\n",
    "        texts.append('')\n",
    "\n",
    "#print(texts)\n",
    "\n",
    "#댓글 : 우회마저 차단당해서 스크립트 확인 불가능해서 나중에 수정할게요\n",
    "\n",
    "\"\"\"\n",
    "for i in links:\n",
    "    try:\n",
    "        res = requests.get(i)\n",
    "        res.raise_for_status()\n",
    "        res.endcoding = None\n",
    "        html2 = res.text\n",
    "\n",
    "        soup = BeautifulSoup(html2, 'html.parser')\n",
    "        contentArea = soup.find(\"div\", {\"class\" : \"content_dummy\"})\n",
    "        parags = contentArea.findAll(\"div\", {\"class\" : \"rd_body clear\"})\n",
    "\n",
    "        content = \"\"\n",
    "\n",
    "        for parag in parags:\n",
    "            content += parag.text\n",
    "        #content = re.sub('[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', content)\n",
    "        #content = re.sub('[ㅋ]', '', content)\n",
    "        #content = re.sub('[&nbsp;|\\n|\\t|\\r]', '', content)\n",
    "        #content = re.sub('[\\xa0]', '', content)\n",
    "        #content = re.sub('[-=+_★♥♡,#/\\?:╋^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》—;]', '', content)\n",
    "        #content = spacing(content)\n",
    "\n",
    "        comments.append(content)\n",
    "        \n",
    "    except HTTPError as e:\n",
    "        comments.append('')\n",
    "    except URLError as e:\n",
    "        comments.append('')\n",
    "    except AttributeError as e:\n",
    "        comments.append('')\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame({'제목' : title, '본문' : texts, '댓글' : comments})\n",
    "df.to_csv('FM_crawling.csv', mode='w', encoding='utf-8-sig')\n",
    "#print(df)\n",
    "\n",
    "hannanum = Hannanum()\n",
    "\n",
    "title_result = []\n",
    "texts_result = []\n",
    "comments_result = []\n",
    "\n",
    "for i in title:\n",
    "    title_result.append(hannanum.morphs(i))\n",
    "\n",
    "for i in texts:\n",
    "    texts_result.append(hannanum.morphs(i))\n",
    "\n",
    "for i in comments:\n",
    "    comments_result.append(hannanum.morphs(i))\n",
    "    \n",
    "df2 = pd.DataFrame({'제목 형태소' : title_result, '본문 형태소' : texts_result, '댓글 형태소' : comments_result'})\n",
    "df2.to_csv('FM_token.csv', mode='w', encoding='utf-8-sig')\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f056d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d14b610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
