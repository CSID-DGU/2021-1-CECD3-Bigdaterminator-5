{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import io\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from konlpy.tag import Okt\n",
    "from urllib.request import HTTPError\n",
    "from urllib.request import URLError\n",
    "import time\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nate_Crawler():\n",
    "    \n",
    "    browser = Chrome()\n",
    "    browser.maximize_window()\n",
    "    base_url = 'https://pann.nate.com'\n",
    "    browser.get(base_url)\n",
    "    \n",
    "    #톡커들의 선택 명예의 전당 - 일상톡 랭킹 - 실시간 (당일 실시간 베스트 게시물)\n",
    "    browser.find_elements_by_xpath('//*[@id=\"container\"]/div[5]/div[2]/div[2]/div[1]/a')[0].click()\n",
    "    browser.find_elements_by_xpath('//*[@id=\"tselect\"]/a')[0].click()\n",
    "    browser.find_elements_by_xpath('//*[@id=\"container\"]/div[3]/div[1]/div[2]/div[2]/ul/li[2]/a')[0].click()\n",
    "    \n",
    "    res = requests.get(browser.current_url)\n",
    "    res.raise_for_status()\n",
    "    res.encoding = None\n",
    "    html = res.text\n",
    "\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    titles = []\n",
    "    links = []\n",
    "\n",
    "    first_list = soup.find('div', {'class': 'cntList'}).findAll('li')\n",
    "\n",
    "    for li in first_list: \n",
    "        f_link = li.findAll('a')\n",
    "        for a in f_link:\n",
    "            real_link = 'https://pann.nate.com' + a.get('href')  \n",
    "        links.append(real_link)\n",
    "\n",
    "    for li in first_list:\n",
    "        f_title = li.findAll('dl')\n",
    "        for dl in f_title:\n",
    "            t = dl.find('a')\n",
    "            real_title = t.get('title')\n",
    "        titles.append(real_title)\n",
    "\n",
    "    browser.find_elements_by_xpath('//*[@id=\"last\"]')[0].click()\n",
    "\n",
    "    res = requests.get(browser.current_url)\n",
    "    res.raise_for_status()\n",
    "    res.encoding = None\n",
    "    html = res.text\n",
    "\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    second_list = soup.find('div', {'class': 'cntList'}).findAll('li')\n",
    "\n",
    "    for li in second_list: \n",
    "        s_link = li.findAll('a')\n",
    "        for a in s_link:\n",
    "            real_link = 'https://pann.nate.com' + a.get('href')  \n",
    "        links.append(real_link)\n",
    "\n",
    "    for li in second_list:\n",
    "        s_title = li.findAll('dl')\n",
    "        for dl in s_title:\n",
    "            t = dl.find('a')\n",
    "            real_title = t.get('title')\n",
    "        titles.append(real_title)\n",
    "\n",
    "\n",
    "    txt = []\n",
    "    \n",
    "    for i in links:\n",
    "        try: \n",
    "            #본문\n",
    "            res = requests.get(i)\n",
    "            res.raise_for_status()\n",
    "            res.encoding = None\n",
    "            html2 = res.text\n",
    "\n",
    "            soup = BeautifulSoup(html2, 'html.parser')\n",
    "            contentArea = soup.find(\"div\", {\"class\" : \"viewarea\"})\n",
    "            parags = contentArea.findAll(\"div\", {\"id\" : \"contentArea\"})\n",
    "\n",
    "            content = \"\"\n",
    "\n",
    "            for parag in parags:\n",
    "                content += parag.text.replace('&nbsp;| |\\t|\\r|\\n|', '')\n",
    "            content = re.sub('[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', content)\n",
    "            content = re.sub('[&nbsp; | &nbsp;| \\n|\\t|\\r]', '', content)\n",
    "            content = re.sub('[\\xa0]', '', content)\n",
    "            content = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', content)\n",
    "            content = re.sub('<[^>]+>','',content)\n",
    "\n",
    "            txt.append(content)\n",
    "             \n",
    "        except HTTPError as e:\n",
    "            txt.append('')\n",
    "        except URLError as e:\n",
    "            txt.append('')\n",
    "        except AttributeError as e:\n",
    "            txt.append('')\n",
    "                      \n",
    "\n",
    "    okt=Okt()\n",
    "    title_morphs = []\n",
    "    txt_morphs = []\n",
    "    \n",
    "    for i in titles:\n",
    "        title_morphs.append(okt.morphs(i))\n",
    "    \n",
    "    for i in txt:\n",
    "        txt_morphs.append(okt.morphs(i))\n",
    "             \n",
    "    \n",
    "    nate_dict = {\n",
    "        '제목' : titles,\n",
    "        '본문' : txt\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(nate_dict) \n",
    "    df.to_csv('natepann.csv', index=False, encoding=\"utf-8-sig\")\n",
    "    \n",
    "    \n",
    "    morphs_dict = {\n",
    "        '제목 형태소' : title_morphs,\n",
    "        '본문 형태소' : txt_morphs\n",
    "    }\n",
    "    df2 = pd.DataFrame(morphs_dict)\n",
    "    df2.to_csv('natepann_Morphs.csv', index=False, encoding=\"utf-8-sig\")\n",
    "    \n",
    "    #browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nate_Crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
