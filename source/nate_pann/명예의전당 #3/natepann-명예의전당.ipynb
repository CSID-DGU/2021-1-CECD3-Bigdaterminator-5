{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import csv\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from konlpy.tag import Komoran, Okt\n",
    "from nltk import Text\n",
    "from pykospacing import spacing\n",
    "import kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Chrome()\n",
    "\n",
    "titles = []\n",
    "links = []\n",
    "\n",
    "for i in range(1,300):\n",
    "    browser.get(\"https://pann.nate.com/search/talk?q=댕댕이\" +\"&page=\" + str(i))\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "    first_list = soup.find('ul', {'class': 's_list'}).findAll('li')\n",
    "    \n",
    "    for li in first_list:\n",
    "        f_title = li.findAll('div', {'class': 'tit'})\n",
    "        for div in f_title:\n",
    "            t = div.findAll('a')[0]['title']\n",
    "            titles.append(t)\n",
    "            \n",
    "    for li in first_list: \n",
    "        f_link = li.findAll('div', {'class': 'txt'})\n",
    "        for div in f_link:\n",
    "            k = div.findAll('a')[0]['href']\n",
    "            real_link = 'https://pann.nate.com' + k\n",
    "            links.append(real_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#본문\n",
    "txt = []\n",
    "    \n",
    "for i in links:\n",
    "    try: \n",
    "        res = requests.get(i)\n",
    "        res.raise_for_status()\n",
    "        res.encoding = None            \n",
    "        html2 = res.text\n",
    "        \n",
    "        soup = BeautifulSoup(html2, 'html.parser')\n",
    "        contentArea = soup.find(\"div\", {\"class\" : \"viewarea\"})            \n",
    "        parags = contentArea.findAll(\"div\", {\"id\" : \"contentArea\"})\n",
    "\n",
    "        content = \"\"\n",
    "\n",
    "        for parag in parags:\n",
    "            content += parag.text\n",
    "            \n",
    "        content = re.sub('[^ ㄱ-ㅣ가-힣]','',content)\n",
    "        \n",
    "        txt.append(content)\n",
    "             \n",
    "    except HTTPError as e:\n",
    "        txt.append('')\n",
    "    except URLError as e:\n",
    "        txt.append('')\n",
    "    except AttributeError as e:\n",
    "        txt.append('')\n",
    "        \n",
    "#print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #형태소 분석\n",
    "# from konlpy.tag import Okt\n",
    "\n",
    "# okt = Okt() \n",
    "\n",
    "# title_morphs = []\n",
    "# txt_morphs = []\n",
    "    \n",
    "# for i in titles:\n",
    "#     title_morphs.append(okt.nouns(i))\n",
    "    \n",
    "# for i in txt:\n",
    "#     txt_morphs.append(okt.nouns(i))\n",
    "    \n",
    "\n",
    "nate_dict = {\n",
    "    '제목' : titles,\n",
    "    '본문' : txt\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(nate_dict) \n",
    "df.to_csv('word.csv', index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "  \n",
    "# morphs_dict = {\n",
    "#     '제목 형태소' : title_morphs,\n",
    "#     '본문 형태소' : txt_morphs\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "# df2 = pd.DataFrame(morphs_dict)\n",
    "# df2.to_csv('word_nouns.csv', index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Chrome()\n",
    "\n",
    "titles = []\n",
    "links = []\n",
    "\n",
    "# date = input(\"시작날짜 입력(eg.20210920):\")\n",
    "#임시 3/1~9/31 데이터 추출\n",
    "#링크, 제목\n",
    "\n",
    "for month in range(3,10):\n",
    "    for date in range(1,32):\n",
    "\n",
    "        for j in range(1,3):\n",
    "            browser.get(\"https://pann.nate.com/talk/ranking/d?stdt=2021\" + str(month).zfill(2) + str(date).zfill(2)+\"&page=\" + str(j))\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "            first_list = soup.find('div', {'class': 'cntList'}).findAll('li')\n",
    "\n",
    "        for li in first_list: \n",
    "            f_link = li.findAll('a')\n",
    "            for a in f_link:\n",
    "                real_link = 'https://pann.nate.com' + a.get('href') \n",
    "            links.append(real_link)\n",
    "\n",
    "        for li in first_list:\n",
    "            f_title = li.findAll('dl')\n",
    "            for dl in f_title:\n",
    "                t = dl.find('a')\n",
    "                real_title = t.get('title')\n",
    "                real_title = re.sub('[^ ㄱ-ㅣ가-힣]','',real_title)\n",
    "#                 real_title = spacing(real_title)\n",
    "#                 real_title = re.sub('[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', real_title)\n",
    "#                 real_title = re.sub('[\\xa0|0xed]', '', real_title)\n",
    "#                 real_title = re.sub('[-=+_★♥♡,#/\\?:╋^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》—;]','',real_title)\n",
    "            titles.append(real_title)\n",
    "\n",
    "\n",
    "#print({'제목': titles, 'url': links}, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#본문\n",
    "txt = []\n",
    "    \n",
    "for i in links:\n",
    "    try: \n",
    "        res = requests.get(i)\n",
    "        res.raise_for_status()\n",
    "        res.encoding = None            \n",
    "        html2 = res.text\n",
    "        \n",
    "        soup = BeautifulSoup(html2, 'html.parser')\n",
    "        contentArea = soup.find(\"div\", {\"class\" : \"viewarea\"})            \n",
    "        parags = contentArea.findAll(\"div\", {\"id\" : \"contentArea\"})\n",
    "\n",
    "        content = \"\"\n",
    "\n",
    "        for parag in parags:\n",
    "            content += parag.text\n",
    "#         content = re.sub('[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', content)\n",
    "#         content = re.sub('[&nbsp;|\\n|\\t|\\r]', '', content)\n",
    "#         content = re.sub('[\\xa0]', '', content)\n",
    "#         content = re.sub('[-=+_★♥♡,#/\\?:╋^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》—;]', '', content)\n",
    "        content = re.sub('[^ ㄱ-ㅣ가-힣]','',content)\n",
    "        #content = spacing(content)\n",
    "        \n",
    "        txt.append(content)\n",
    "             \n",
    "    except HTTPError as e:\n",
    "        txt.append('')\n",
    "    except URLError as e:\n",
    "        txt.append('')\n",
    "    except AttributeError as e:\n",
    "        txt.append('')\n",
    "        \n",
    "#print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt() \n",
    "\n",
    "title_morphs = []\n",
    "txt_morphs = []\n",
    "    \n",
    "for i in titles:\n",
    "    title_morphs.append(okt.nouns(i))\n",
    "    \n",
    "for i in txt:\n",
    "    txt_morphs.append(okt.nouns(i))\n",
    "    \n",
    "\n",
    "nate_dict = {\n",
    "    '제목' : titles,\n",
    "    '본문' : txt\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(nate_dict) \n",
    "df.to_csv('natepann.csv', index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "  \n",
    "morphs_dict = {\n",
    "    '제목 형태소' : title_morphs,\n",
    "    '본문 형태소' : txt_morphs\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(morphs_dict)\n",
    "df2.to_csv('natepann_nouns.csv', index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
