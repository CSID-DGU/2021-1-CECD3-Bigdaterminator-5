{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import csv\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iframe 제거 후 blog.naver.com 붙이기\n",
    "def delete_iframe(url):\n",
    "    browser.get(url)\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "    src_url = \"https://blog.naver.com/\" + soup.iframe[\"src\"]\n",
    "    \n",
    "    return src_url\n",
    "\n",
    "\n",
    "# 본문 스크래핑\n",
    "def text_scraping(url):\n",
    "    browser.get(url)\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "    if soup.find(\"div\", attrs={\"class\":\"se-main-container\"}):\n",
    "        text = soup.find(\"div\", attrs={\"class\":\"se-main-container\"}).get_text()\n",
    "        text = text.replace(\"\\n\",\"\")\n",
    "        return text\n",
    "\n",
    "    elif soup.find(\"div\", attrs={\"id\":\"postViewArea\"}):\n",
    "        text = soup.find(\"div\", attrs={\"id\":\"postViewArea\"}).get_text()\n",
    "        text = text.replace(\"\\n\",\"\") \n",
    "        return text\n",
    "    else:\n",
    "        return \"확인불가\"\n",
    "    \n",
    "    \n",
    "def doScrollDown(whileSeconds):\n",
    "    start = datetime.datetime.now()\n",
    "    end = start + datetime.timedelta(seconds=whileSeconds)\n",
    "    while True:\n",
    "        browser.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(1)\n",
    "        if datetime.datetime.now() > end:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from urllib.parse import quote\n",
    "\n",
    "browser = Chrome()\n",
    "\n",
    "query = \"댕댕이\" # 키워드 입력\n",
    "\n",
    "url = \"https://search.naver.com/search.naver?where=view&sm=tab_jum&query=\" + quote(query)\n",
    "\n",
    "browser.get(url)\n",
    "\n",
    "doScrollDown(10)\n",
    "    \n",
    "soup = BeautifulSoup(browser.page_source, 'html.parser')    \n",
    "posts = soup.find_all(\"li\", attrs={\"class\":\"bx _svp_item\"})\n",
    "\n",
    "\n",
    "for post in posts:\n",
    "    post_title = post.find(\"a\", attrs={\"class\":\"api_txt_lines total_tit _cross_trigger\"}).get_text()\n",
    "\n",
    "    post_link = post.find(\"a\", attrs={\"class\":\"api_txt_lines total_tit _cross_trigger\"})['href']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "\n",
    "for post in posts:\n",
    "    post_title = post.find(\"a\", attrs={\"class\":\"api_txt_lines total_tit _cross_trigger\"}).get_text()\n",
    "    post_link = post.find(\"a\", attrs={\"class\":\"api_txt_lines total_tit _cross_trigger\"})['href']\n",
    "    \n",
    "    blog_p = re.compile(\"blog.naver.com\")\n",
    "    blog_m = blog_p.search(post_link)\n",
    "    \n",
    "    if blog_m:\n",
    "        blog_text = text_scraping(delete_iframe(post_link))\n",
    "        \n",
    "        blog_t=(re.sub('[ㄱ-ㅎㅏ-ㅣ]', '', blog_text))\n",
    "        blog_t=(re.sub('[\\xa0|0xed]', '', blog_t))\n",
    "        blog_t=(re.sub('[a-zA-Z0-9一-龥]', '', blog_t))\n",
    "        #blog_t=(re.sub('[-=+,#/\\?:^@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·★•♥❤️♪♬♡▪%♠▶]', ' ', blog_t))\n",
    "        blog_t=(re.sub('[-=+,#/\\?:^@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·]', '', blog_t))\n",
    "        blog_t=(re.sub('[\\U00010000-\\U0010FFFF\"]', '', blog_t))\n",
    "            \n",
    "        f = open('naver_data.txt', 'a',encoding='utf8')\n",
    "        f.write(post_title + '\\n' + blog_t + '\\n')\n",
    "        f.close()\n",
    "        \n",
    "        #print(post_title + '\\n' + blog_t + '\\n')\n",
    "        #print(\"-\"*50)\n",
    "        \n",
    "#browser.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import hgtk # 자음 모음 관리\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab, Okt\n",
    "\n",
    "compose_code = \"\\u33c6\"\n",
    "\n",
    "def _jamo_sentence(sent):\n",
    "    doublespace_pattern = re.compile(r\"\\s+\")\n",
    "\n",
    "    def __transform(char):\n",
    "        if char == \" \":\n",
    "            return char\n",
    "        cjj = hgtk.text.decompose(char, compose_code)\n",
    "        if not cjj:\n",
    "            return char\n",
    "        if len(cjj) == 1:\n",
    "            return cjj\n",
    "        cjj_ = \"\".join(c if c != \" \" else compose_code for c in cjj)\n",
    "        return cjj_\n",
    "\n",
    "    sent_ = \"\".join(__transform(char) for char in sent)\n",
    "    sent_ = doublespace_pattern.sub(\" \", sent_) # 두칸 이상 공백을 1칸 공백으로\n",
    "    return sent_\n",
    "\n",
    "\n",
    "def trans(char):\n",
    "    if char == \" \":\n",
    "        return char\n",
    "    cjj = hgtk.text.decompose(char, compose_code)\n",
    "    if not cjj:\n",
    "        return char\n",
    "    if len(cjj) == 1:\n",
    "        return cjj\n",
    "    cjj_ = \"\".join(c if c != \" \" else compose_code for c in cjj)\n",
    "    return cjj_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('naver_data.txt','r', encoding='utf-8') as f:\n",
    "    datafile = f.readlines()\n",
    "    datafile = ''.join(datafile)\n",
    "    datafile=(re.sub(r'[^ ㄱ-ㅣ가-힣]', '', datafile))\n",
    "    datafile=(re.sub(r'[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', datafile))\n",
    "\n",
    "    datafile=_jamo_sentence(datafile)\n",
    "    #print(datafile)\n",
    "    \n",
    "    f = open('naver_re_data.txt', 'a',encoding='utf8')\n",
    "    f.write(datafile)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt() \n",
    "data = []\n",
    "\n",
    "with open('naver_data.txt','r', encoding='utf-8') as f:\n",
    "    datafile = f.readlines()\n",
    "    datafile = ''.join(datafile)\n",
    "    datafile=(re.sub(r'[^ ㄱ-ㅣ가-힣]', '', datafile))\n",
    "    data.append(okt.nouns(datafile))\n",
    "    #print(data)\n",
    "    \n",
    "    t = open('naver_noun.txt', 'w', encoding='utf-8')\n",
    "    for i in data:\n",
    "        t.write(str(i))\n",
    "        t.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 중\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import fasttext\n",
    "\n",
    "save = 'naver_data.txt'\n",
    "model_fname = 'data_result.bin'\n",
    "\n",
    "print(\"학습 중\")\n",
    "model1 = fasttext.train_unsupervised(\n",
    "    input=save,\n",
    "    model='cbow',\n",
    "    loss='hs',\n",
    "    ws=11,\n",
    "    lr=0.0001,\n",
    "    dim=10,\n",
    "    epoch=1000,\n",
    "    min_count=5,\n",
    "    thread=12,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model1.save_model(model_fname)\n",
    "print('완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9838256239891052, '사실'),\n",
       " (0.9823348522186279, '강아지를'),\n",
       " (0.9820657968521118, '댕댕이는'),\n",
       " (0.9797086715698242, '댕댕이들'),\n",
       " (0.9775006175041199, '경우'),\n",
       " (0.9774555563926697, '강아지와'),\n",
       " (0.9769712686538696, '댕댕이가'),\n",
       " (0.9754970669746399, '강아지는'),\n",
       " (0.9742645025253296, '강아지'),\n",
       " (0.9709970355033875, '있는')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#문장 학습 - 형태 유사어 추출\n",
    "model1 = fasttext.load_model('data_result.bin')\n",
    "model1.get_nearest_neighbors(\"댕댕이\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 명사 형태로 이미 전처리 후 하는 것은 의미 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 중\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "save2 = 'naver_noun.txt'\n",
    "model_fname2 = 'noun_result.bin'\n",
    "\n",
    "print(\"학습 중\")\n",
    "model2 = fasttext.train_unsupervised(\n",
    "    input=save2,\n",
    "    model='cbow',\n",
    "    loss='hs',\n",
    "    ws=11,\n",
    "    lr=0.0001,\n",
    "    dim=50,\n",
    "    epoch=100,\n",
    "    min_count=5,\n",
    "    thread=12,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model2.save_model(model_fname2)\n",
    "print('완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0744122564792633, \"'견사',\"),\n",
       " (0.040044598281383514, \"'애기',\"),\n",
       " (0.03915612772107124, \"'봉사',\"),\n",
       " (0.03486886993050575, \"'말티즈',\"),\n",
       " (0.033787600696086884, \"'가면',\"),\n",
       " (0.033252838999032974, \"'공간',\"),\n",
       " (0.03272876888513565, \"'이기',\"),\n",
       " (0.029834795743227005, \"'연신내',\"),\n",
       " (0.02892761118710041, \"'실제',\"),\n",
       " (0.027488719671964645, \"'다리',\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#명사 학습 - 형태 유사어 추출\n",
    "model2 = fasttext.load_model('noun_result.bin')\n",
    "model2.get_nearest_neighbors(\"댕댕이\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자소 단위 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 중\n"
     ]
    }
   ],
   "source": [
    "#자소단위 텍스트 학습\n",
    "save3 = 'naver_re_data.txt'\n",
    "model_fname3 = 're_result.bin'\n",
    "\n",
    "print(\"학습 중\")\n",
    "model3 = fasttext.train_unsupervised(\n",
    "    input=save3,\n",
    "    model='cbow',\n",
    "    loss='hs',\n",
    "    ws=11,\n",
    "    lr=0.0001,\n",
    "    dim=10,\n",
    "    epoch=1000,\n",
    "    min_count=5,\n",
    "    thread=12,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model3.save_model(model_fname3)\n",
    "print('완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9806052446365356, 'ㅊㅐㅇᴥㄱㅣㄹᴥ'),\n",
       " (0.9792996048927307, 'ㅈㅓㅇᴥㅌㅗㅇᴥㅇㅢᴥ'),\n",
       " (0.9792307019233704, 'ㅇㅢᴥ'),\n",
       " (0.9751275181770325, 'ㅁㅏᴥㅇㅡㅁᴥㅇㅢᴥ'),\n",
       " (0.9741119742393494, 'ㅈㅓㄴᴥㅌㅗㅇᴥㄱㅘᴥ'),\n",
       " (0.9738455414772034, 'ㅂㅡᴥㄹㅐㄴᴥㄷㅡᴥ'),\n",
       " (0.9699309468269348, 'ㅅㅏᴥㄹㅏㅇᴥㄱㅘᴥ'),\n",
       " (0.9669359922409058, 'ㅇㅕㅇᴥㅅㅏㅇᴥㅇㅢᴥ'),\n",
       " (0.9663962721824646, 'ㅇㅑㅇᴥㅇㅢᴥ'),\n",
       " (0.9659558534622192, 'ㅇㅟᴥㅎㅐᴥ')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.hangle import compose, decompose, character_is_korean\n",
    "\n",
    "#자소단위 학습 - 형태 유사어 추출\n",
    "model3 = fasttext.load_model('re_result.bin')\n",
    "model3.get_nearest_neighbors(\"댕댕이\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['챙길', '정통의', '의', '마음의', '전통과', '브랜드', '사랑과', '영상의', '양의', '위해']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hgtk.text.compose(found) for found in [word for score, word in model3.get_nearest_neighbors('댕댕이')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의미 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 104/104 [00:00<00:00, 26068.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus 생성\n",
      "학습 중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n",
      "(552, 100)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import fasttext\n",
    "\n",
    "corpus_fname = 'naver_data.txt'\n",
    "model_fname = 'fasttext'\n",
    "\n",
    "\n",
    "print('corpus 생성')\n",
    "corpus = [sent.strip().split(\" \")for sent in tqdm(open(corpus_fname, 'r', encoding='utf-8').readlines())]\n",
    "\n",
    "print(\"학습 중\")\n",
    "model = FastText(corpus, vector_size=100, window=5, min_count=5, workers=4, sg=1)\n",
    "model.save(model_fname)\n",
    "print('완료')\n",
    "\n",
    "loaded_model = FastText.load(\"fasttext\")\n",
    "print(model.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('댕댕이삼계탕', 0.9992862343788147), ('강아지삼계탕', 0.9992821216583252), ('강아지옷', 0.9992791414260864), ('퓨어메라', 0.9992114901542664), ('이벤트', 0.9991117119789124), ('강아지간식', 0.999061107635498), ('강아지', 0.9990420937538147), ('강아지옷만들기', 0.9990110397338867), ('중입니다.분', 0.9989457130432129), ('애견용품', 0.998928427696228)]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.wv.most_similar(\"댕댕이\", topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
