{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import csv\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from konlpy.tag import Komoran\n",
    "from nltk import Text\n",
    "from pykospacing import spacing\n",
    "import kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Chrome()\n",
    "\n",
    "titles = []\n",
    "links = []\n",
    "    \n",
    "#링크, 제목\n",
    "for i in range(1,3):\n",
    "    browser.get(\"https://pann.nate.com/talk/ranking?rankingType=life&page=\" + str(i))\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "    first_list = soup.find('div', {'class': 'cntList'}).findAll('li')\n",
    "\n",
    "    for li in first_list: \n",
    "        f_link = li.findAll('a')\n",
    "        for a in f_link:\n",
    "            real_link = 'https://pann.nate.com' + a.get('href') \n",
    "        links.append(real_link)\n",
    "    \n",
    "    for li in first_list:\n",
    "        f_title = li.findAll('dl')\n",
    "        for dl in f_title:\n",
    "            t = dl.find('a')\n",
    "            real_title = t.get('title')\n",
    "            real_title = spacing(real_title)\n",
    "            real_title = re.sub('[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', real_title)\n",
    "            real_title = re.sub('[\\xa0|0xed]', '', real_title)\n",
    "            real_title = re.sub('[-=+_★♥♡,#/\\?:╋^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》—;]','',real_title)\n",
    "        titles.append(real_title)\n",
    "\n",
    "#print({'제목': titles, 'url': links}, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#본문\n",
    "txt = []\n",
    "    \n",
    "for i in links:\n",
    "    try: \n",
    "        res = requests.get(i)\n",
    "        res.raise_for_status()\n",
    "        res.encoding = None            \n",
    "        html2 = res.text\n",
    "        \n",
    "        soup = BeautifulSoup(html2, 'html.parser')\n",
    "        contentArea = soup.find(\"div\", {\"class\" : \"viewarea\"})            \n",
    "        parags = contentArea.findAll(\"div\", {\"id\" : \"contentArea\"})\n",
    "\n",
    "        content = \"\"\n",
    "\n",
    "        for parag in parags:\n",
    "            content += parag.text\n",
    "        content = re.sub('[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', content)\n",
    "        content = re.sub('[&nbsp;|\\n|\\t|\\r]', '', content)\n",
    "        content = re.sub('[\\xa0]', '', content)\n",
    "        content = re.sub('[-=+_★♥♡,#/\\?:╋^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》—;]', '', content)\n",
    "        content = spacing(content)\n",
    "        \n",
    "        txt.append(content)\n",
    "             \n",
    "    except HTTPError as e:\n",
    "        txt.append('')\n",
    "    except URLError as e:\n",
    "        txt.append('')\n",
    "    except AttributeError as e:\n",
    "        txt.append('')\n",
    "        \n",
    "#print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#댓글\n",
    "comments =[]\n",
    "\n",
    "for i in links:\n",
    "    try: \n",
    "        res = requests.get(i)\n",
    "        res.raise_for_status()\n",
    "        res.encoding = None            \n",
    "        html2 = res.text\n",
    "        \n",
    "        soup = BeautifulSoup(html2, 'html.parser')\n",
    "        contentArea = soup.find(\"div\", {\"class\" : \"cmt_list\"})            \n",
    "        parags = contentArea.findAll(\"dd\", {\"class\" : \"usertxt\"})\n",
    "        \n",
    "        content = \"\"\n",
    "\n",
    "        for parag in parags:\n",
    "            content += parag.text\n",
    "        content = re.sub('[ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', '', content)\n",
    "        content = re.sub('[&nbsp;|\\n|\\t|\\r]', '', content)\n",
    "        content = re.sub('[\\xa0]', '', content)\n",
    "        content = re.sub('[-=+_★♥♡,#/\\?:╋^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》—;]', '', content)    \n",
    "        content = spacing(content)\n",
    "        \n",
    "        comments.append(content)\n",
    "    \n",
    "    except HTTPError as e:\n",
    "        txt.append('')\n",
    "    except URLError as e:\n",
    "        txt.append('')\n",
    "    except AttributeError as e:\n",
    "        txt.append('')\n",
    "\n",
    "#print(comments)\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['갈등']\",\n",
       " \"['결혼']\",\n",
       " \"['남녀']\",\n",
       " \"['남자']\",\n",
       " \"['남편']\",\n",
       " \"['부모']\",\n",
       " \"['여자']\",\n",
       " \"['유발']\",\n",
       " \"['자기']\",\n",
       " \"['친구']\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = pd.read_csv('10키워드s.csv', encoding='utf-8')\n",
    "keyword.values\n",
    "klist = []\n",
    "\n",
    "for i in keyword.values:\n",
    "    klist.append(str(i))\n",
    "\n",
    "#for문 추가 - 10개 loop\n",
    "klist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석\n",
    "komoran = Komoran() \n",
    "\n",
    "title_morphs = []\n",
    "txt_morphs = []\n",
    "comment_morphs = []\n",
    "\n",
    "\n",
    "for i in titles:\n",
    "    title_morphs.append(komoran.morphs(i))\n",
    "    \n",
    "for i in txt:\n",
    "    txt_morphs.append(komoran.morphs(i))\n",
    "    \n",
    "for i in comments:\n",
    "    comment_morphs.append(komoran.morphs(i))  \n",
    "        \n",
    "nate_dict = {\n",
    "    '제목' : titles,\n",
    "    '본문' : txt,\n",
    "    '댓글' : comments\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(nate_dict) \n",
    "df.to_csv('natepann.csv', index=False, encoding=\"utf-8-sig\")\n",
    "    \n",
    "morphs_dict = {\n",
    "    '제목 형태소' : title_morphs,\n",
    "    '본문 형태소' : txt_morphs,\n",
    "    '댓글 형태소' : comment_morphs\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(morphs_dict)\n",
    "df2.to_csv('natepann_Morphs.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #형태소 분석\n",
    "# komoran = Komoran() \n",
    "\n",
    "# title_morphs = []\n",
    "# txt_morphs = []\n",
    "# comment_morphs = []\n",
    "\n",
    "# key = '갈등'\n",
    "\n",
    "# for i in titles:\n",
    "#     if key in i:\n",
    "#         title_morphs.append(komoran.morphs(i))\n",
    "    \n",
    "# for i in txt:\n",
    "#     if key in i:\n",
    "#         txt_morphs.append(komoran.morphs(i))\n",
    "    \n",
    "# for i in comments:\n",
    "#     if key in i:\n",
    "#         comment_morphs.append(komoran.morphs(i))  \n",
    "        \n",
    "# morphs_dict = {\n",
    "#     '제목 형태소' : title_morphs,\n",
    "#     '본문 형태소' : txt_morphs,\n",
    "#     '댓글 형태소' : comment_morphs\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(nate_dict) \n",
    "# df.to_csv('keyword#1.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
